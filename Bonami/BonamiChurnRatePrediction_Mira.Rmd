---
title: "Predicting churn rate among e-commerce customers"
author: "AGUIAR DE OLIVEIRA RICARDO Sara, FERREIRA Ricardo, KHOLODOV Slava, RIBEIRO Joana, SALA Miroslav"
output:
  html_document:
    css: ../AnalyticsStyles/default.css
    theme: paper
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    includes:
      in_header: ../AnalyticsStyles/default.sty
always_allow_html: yes
---

<!-- **Note:** Assuming the working directory is "MYDIRECTORY/INSEADAnalytics" (where you have cloned the course material), you can create an html file by running in your console the command rmarkdown::render("CourseSessions/ClassificationProcessCreditCardDefault.Rmd") -->

```{r echo=FALSE, message=FALSE}
make_pdf_file = 0 # SET THIS TO 1 IF WE COMPILE PDF FILE, 0 OTHERWISE (FOR HTML)

source("../AnalyticsLibraries/library.R")
source("../AnalyticsLibraries/heatmapOutput.R")

# Package options
ggthemr('fresh')  # ggplot theme
opts_knit$set(progress=FALSE, verbose=FALSE)
opts_chunk$set(echo=FALSE, fig.align="center", fig.width=10, fig.height=6.2)
options(knitr.kable.NA = '')
```

```{r echo=FALSE, message=FALSE}
# Please ENTER the filename
datafile_name = "../Data/UCI_Credit_Card.csv"
ProjectData <- read.csv(datafile_name)
# We turn the data into data.matrix class so that we can easier manipulate it
ProjectData <- data.matrix(ProjectData)

# Please ENTER the dependent variable (class).
# Please use numbers, not column names. E.g., 82 uses the 82nd column as the dependent variable.
# You need to make sure that dependent variable takes only two values: 0 and 1.
dependent_variable = 25

# Please ENTER the attributes to use as independent variables. 
# Please use numbers, not column names. E.g., c(1:5, 7, 8) uses columns 1,2,3,4,5,7,8.
independent_variables = c(1:24) # use all the available attributes

dependent_variable = unique(sapply(dependent_variable,function(i) min(ncol(ProjectData), max(i,1))))
independent_variables = unique(sapply(independent_variables,function(i) min(ncol(ProjectData), max(i,1))))

if (length(unique(ProjectData[,dependent_variable])) !=2){
  cat("\n*****\n BE CAREFUL, THE DEPENDENT VARIABLE TAKES MORE THAN 2 VALUES")
  cat("\nSplitting it around its median...\n*****\n ")
  new_dependent = ProjectData[,dependent_variable] >= median(ProjectData[,dependent_variable])
  ProjectData[,dependent_variable] <- 1*new_dependent
}

# Please ENTER the probability threshold above which an observation is predicted as class 1:
Probability_Threshold = 0.5 # between 0 and 1

# Please ENTER the percentage of data used for estimation
estimation_data_percent = 80
validation_data_percent = 10
test_data_percent = 100-estimation_data_percent-validation_data_percent

# Please ENTER 1 if you want to randomly split the data in estimation and validation/test
random_sampling = 1

# Tree parameter
# Please ENTER the tree (CART) complexity control cp (e.g. 0.0001 to 0.02, depending on the data)
CART_cp = 0.0025
CART_control = rpart.control(cp = CART_cp)

# Please ENTER the words for the business interpretation of class 1 and class 0:
class_1_interpretation = "default"
class_0_interpretation = "no default"

# Please ENTER the profit/cost values for correctly classified and misclassified data:
actual_1_predict_1 = 0
actual_1_predict_0 = -100000
actual_0_predict_1 = 0
actual_0_predict_0 = 20000

Profit_Matrix = matrix(c(actual_1_predict_1, actual_0_predict_1, actual_1_predict_0, actual_0_predict_0), ncol=2)
colnames(Profit_Matrix) <- c(paste("Predict 1 (", class_1_interpretation, ")", sep = ""), paste("Predict 0 (", class_0_interpretation, ")", sep = ""))
rownames(Profit_Matrix) <- c(paste("Actual 1 (", class_1_interpretation, ")", sep = ""), paste("Actual 0 (", class_0_interpretation, ")", sep = ""))

# Please ENTER the maximum number of observations to show in the report and slides 
# (DEFAULT is 50. If the number is large the report and slides may not be generated - very slow or will crash!!)
max_data_report = 10 
```

# Description of the Business Problem
Chezk-based e-commerce startup, Bonami, that sells furniture and accesories wants to answer 3 questions about its customers: 

1. What behavior / factors predicts customer churn?
2. Which currently active customers are most likely to churn and how to prevent it?
3. How to increase frequency of orders among active customers?

Answers to those questions would allow Bonami to understand behaviour of its customers better as well as lower their churn rate and increase sales to active customers. 

<hr>\clearpage

# Business Solution Process
To answer above questions, we will go over the following process:

1. We will work on the "per customer" level of data
2. We will create new variables that make business rationale for predicting customers churn. Such variables will include (for each of 21 months of data) order revenues, number of orders, discount amounts receivced by customers, number of individual items bought, product categories bought, number of days passed since last order, to name a few.
3. We will split the data in 3 data sets - training, validation and test samples. Steps 5-8 below will then be performed only on the training and validation sets. Step 9 will be performed on test sample **to make final business decisions**. 
4. We will define "churned customers" as customers who didn't buy anything during the last X months. X will depend on mean and standard deviation of the average number of orders per customer over the last 21 months. We will then introduce new variable "churned customers" and label customers as "churned" or "active". This will be our dependent variable (it will be a factor). **We will also generate trailing flags - i.e. Active in T90 days will be set up to 1 if the customer was active buyer in trailing 90 days. We thought about trailing periods of 60, 180, and 365 days to mimic the churn methodology of a famous e-commerce company with which our team had working experience. **
5. Since predicting probability of churn is esentially predicting a binary event, we will use appropriate data analysis tools such as step-wise logistic regression and CART (classification and regression tree) to discover significant explanatory variables and build the model. 
6. We will assess importance of the explanatory variables using visualization tools and simple descriptive statistics **of the regression coefficients and CART statistics **.
7. We will estimate classification models using the training dataset, and interpret the results.
8. We will **assess** the accuracy of classification making prediction on the validation sample, possibly repeating steps 5-7 a few times changing the classifier in different ways to increase performance.
9. We will assess the accuracy of classification on the test sample. 
10. We will make prediction for customers churn based on their behaviour. We will now include last X months, that initially were used to classify customers as "churned" or "active", to make future churn prediction. 

<hr>\clearpage

# The Data Summary and Descriptive Statistics
The data on Bonami customers transactions was obtained directly from Bonami's management team.

The startup has gathered information on `r nrow(ProjectData)` product items transactions on per-item basis. The dataset contains information on `r length(independent_variables)` variables, including individual order revenues, amount of delivery and payment fees, amount of order discounts, purchasing prices from suppliers, product categories and brands, customer satisfaction variables, order dates, etc. as well as information on individual product items that constituted the order.    

The dataset contains information about transactions that happened between 01/01/2016 and 15/09/2017, i.e. more than 1.5 years of data.

Name                       | Description
:--------------------------|:--------------------------------------------------------------------
order ID                   | ID of each order
order pack ID              | ID of order package
customer ID                | ID of each customer
product_id                 | ID of individual product items from the order
date order creation        | Date when order was created
promised delivery date     | Date by when Bonami promised to deliver the order
shipping date from warehouse | Date when order was shipped from warehouse. Typically, it reachs customer 2 days later
date first order           |Date of the 1st order made by the customer
currency_order             |Currency in which payment for the order was made
order revenue, CZK         |Total order revenue with VAT in Czech Koruna
delivery fee_order, CZK    |Delivery fee per order in Czech Koruna
payment fee_order, CZK     |Payment fee per order in Czech Koruna
order discount, CZK        |Order discount in Czech Koruna
purchase price supplier_order, CZK              |Purchase price from Bonami's suppliers without VAT in Czech Koruna
product category           |Product item category
product brand              |Product item brand
stock sale flag            |Flag of selling directly from stock ("1"" for quick delivery from stock, other numbers otherwise)
unit price, CZK            |Unit price of individual product item with VAT in Czech Koruna
number ordered units       |Number of ordered units of individual product item
product discount, CZK      |Individual product item discount in Czech Koruna
purchase price supplier_product, CZK              |Purchase price for individual product items from Bonami's suppliers without VAT in Czech Koruna
number units returned      |Number of items returned by customers to Bonami
payment_status             |Payment status of the order
payment method             |Payment method of the order
delivery method            |Delivery method of the order
ZIP number                 |ZIP code of order delivery address
satisfied                  |Customer satisfaction with the whole order
delivery_date_satisfied    |Customer satisfaction with delivery dates
packing_satisfied          |Customer satisfaction with packaging
delivery_satisfied         |Customer satisfaction with delivery
recommend                  |Customer willingness to recommend Bonami to others
marketing source           |Marketing channel that customer came from
gross profit_order, CZK    |Gross profit per order in Czech Koruna
gross profit_product, CZK  |Gross profit per individual product items in Czech Koruna
gross profit %_order       |Gross profit margin per order
gross profit %_product     |Gross profit margin per individual product items
promised # days to deliver |Promised number of days to deliver the order 
actual # days to deliver   |Actual (estimated) number of days to deliver the order
early delivery flag        |Flag if order was delivered earlier than promised
order discount %           |Order discount percentage
product discount %         |Individual product items discount percentage


Let's look into the data for a few customers. This is how the first `r min(max_data_report, nrow(ProjectData))` out of the total of `r nrow(ProjectData)` rows look like (transposed, for convenience):

```{r echo=FALSE, message=FALSE, prompt=FALSE, results='asis'}
knitr::kable({
  df <- t(head(round(ProjectData[,independent_variables],2), max_data_report))
  colnames(df) <- sprintf("%02d", 1:ncol(df))
  df
})
```

<hr>\clearpage


# A Process for Classification

> It is important to remember that data analytics projects require a delicate balance between experimentation, intuition, and following a process. The value of following a process is so as to avoid getting fooled by randomness in data and finding "results and patterns" that are mainly driven by our own biases and not by the facts/data themselves.

*There is no single best process* for classification. However, we have to start somewhere, so we will use the following process:

1. Create an estimation sample and two validation samples by splitting the data into three groups. Steps 2-5 below will then be performed only on the estimation and the first validation data. You should only do step 6 once on the second validation data, also called **test data**, and only report/use the performance on that (second validation) data to make final business decisions. 
2. Set up the dependent variable (as a categorical 0-1 variable; multi-class classification is also feasible, and similar, but we do not explore it in this note). 
3. Make a preliminary assessment of the relative importance of the explanatory variables using visualization tools and simple descriptive statistics. 
4. Estimate the classification model using the estimation data, and interpret the results.
5. Assess the accuracy of classification in the first validation sample, possibly repeating steps 2-5 a few times changing the classifier in different ways to increase performance.
6. Finally, assess the accuracy of classification in the second validation sample. You should eventually use and report all relevant performance measures and plots on this second validation sample only.

Let's follow these steps.


## Step 1: Split the data 
It is very important that you (or the data scientists working on the project) finally measure and report the performance of the models on **data that have not been used at all during the analysis, called "out-of-sample" or test data** (steps 2-5 above). The idea is that in practice we want our models to be used for predicting the class of observations/data we have not seen yet (i.e., "the future data"): although the performance of a classification method may be high in the data used to estimate the model parameters, it may be significantly poorer on data not used for parameter estimation, such as the **out-of-sample** (future) data. 

This is why we split the data into an estimation sample and two validation samples  - using some kind of randomized splitting technique. The second validation data mimic out-of-sample data, and the performance on this validation set is a better approximation of the performance one should expect in practice from the selected classification method. The estimation data and the first validation data are used during steps 2-5 (with a few iterations of these steps), while the second validation data is only used once at the very end before making final business decisions based on the analysis. The split can be, for example, 80% estimation, 10% validation, and 10% test data, depending on the number of observations - for example, when there is a lot of data, you may only keep a few hundreds of them for the validation and test sets, and use the rest for estimation. 

While setting up the estimation and validation samples, you should also check that the same proportion of data from each class (i.e., customers who default versus not) are maintained in each sample. That is, you should maintain the same balance of the dependent variable categories as in the overall dataset. 

For simplicity, in this note we will not iterate steps 2-5. In practice, however, we should usually iterate steps 2-5 a number of times using the first validation sample each time, and at the end make our final assessment of the classification model using the test sample only once. 

```{r echo=FALSE}
if (random_sampling){
  estimation_data_ids=sample.int(nrow(ProjectData),floor(estimation_data_percent*nrow(ProjectData)/100))
  non_estimation_data = setdiff(1:nrow(ProjectData),estimation_data_ids) #setdiff(x,y) returns the elements of x that are not in y
  validation_data_ids=non_estimation_data[sample.int(length(non_estimation_data), floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(non_estimation_data)))]
  } else {
    estimation_data_ids=1:floor(estimation_data_percent*nrow(ProjectData)/100)
    non_estimation_data = setdiff(1:nrow(ProjectData),estimation_data_ids)
    validation_data_ids = (tail(estimation_data_ids,1)+1):(tail(estimation_data_ids,1) + floor(validation_data_percent/(validation_data_percent+test_data_percent)*length(non_estimation_data)))
    }

test_data_ids = setdiff(1:nrow(ProjectData), union(estimation_data_ids,validation_data_ids))

estimation_data=ProjectData[estimation_data_ids,]
validation_data=ProjectData[validation_data_ids,]
test_data=ProjectData[test_data_ids,]
```

We typically refer to the three data samples as **estimation data** (`r estimation_data_percent`% of the data in our case), **validation data**  (`r validation_data_percent`% of the data) and **test data** (the remaining `r 100 - estimation_data_percent  -  validation_data_percent`% of the data).

In our case we use `r nrow(estimation_data)` observations in the estimation data, `r nrow(validation_data)` in the validation data, and `r nrow(test_data)` in the test data. 



## Step 2: Set up the dependent variable
First, make sure the dependent variable is set up as a categorical 0-1 variable. In our illustrative example, we use the payment default (or no default) as the dependent variable. 

The data however may not be always readily available with a categorical dependent variable. Suppose a retailer wants to understand what discriminates consumers who are  loyal versus those who are not. If they have data on the amount that customers spend in their store or the frequency of their purchases, they can create a categorical variable ("loyal vs. not loyal") by using a definition such as: "A loyal customer is one who spends more than X amount at the store and makes at least Y purchases a year". They can then code these loyal customers as "1" and the others as "0". They can choose the thresholds X and Y as they wish: a definition/decision that may have a big impact in the overall analysis. This decision can be the most crucial one of the whole data analysis: a wrong choice at this step may lead both to poor performance later as well as to no valuable insights. One should revisit the choice made at this step several times, iterating steps 2-3 and 2-5.

> Carefully deciding what the dependent 0/1 variable is can be the most critical choice of a classification analysis. This decision typically depends on contextual knowledge and needs to be revisited multiple times throughout a data analytics project. 

In our data the number of 0/1's in our estimation sample is as follows:

```{r echo=FALSE}
class_percentages=matrix(c(sum(estimation_data[,dependent_variable]==1),sum(estimation_data[,dependent_variable]==0)), nrow=1); colnames(class_percentages)<-c("Class 1", "Class 0")
rownames(class_percentages)<-"# of Observations"
knitr::kable(class_percentages)
```

while in the validation sample they are:

```{r echo=FALSE}
class_percentages=matrix(c(sum(validation_data[,dependent_variable]==1),sum(validation_data[,dependent_variable]==0)), nrow=1); colnames(class_percentages)<-c("Class 1", "Class 0")
rownames(class_percentages)<-"# of Observations"
knitr::kable(class_percentages)
```


## Step 3: Simple Analysis
Good data analytics start with good contextual knowledge as well as a simple statistical and visual exploration of the data. In the case of classification, one can explore "simple classifications" by assessing how the classes differ along any of the independent variables. For example, these are the statistics of our independent variables across the two classes in the estimation data, class 1 ("default"):

```{r echo=FALSE}
knitr::kable(round(my_summary(estimation_data[estimation_data[,dependent_variable]==1,independent_variables]),2))
```

and class 0 ("no default"):

```{r echo=FALSE}
knitr::kable(round(my_summary(estimation_data[estimation_data[,dependent_variable]==0,independent_variables]),2))
```

The purpose of such an analysis by class is to get an initial idea about whether the classes are indeed separable as well as to understand which of the independent variables have most discriminatory power. 

Notice however that

> Even though each independent variable may not differ across classes, classification may still be feasible: a (linear or nonlinear) combination of independent variables may still be discriminatory. 

A simple visualization tool to assess the discriminatory power of the independent variables are the **box plots**. A box plot visually indicates simple summary statistics of an independent variable (e.g. mean, median, top and bottom quantiles, min, max, etc.). For example consider the box plots for our estimation data for the repayment status variables, for class 1

```{r echo=FALSE, fig.height=4.5}
# Please ENTER the selected independent variables for which to draw box plots. 
# Please use numbers, not column names. E.g., c(1:5, 7, 8) uses columns 1,2,3,4,5,7,8.
boxplots_independent_variables = c(7:12) # use only the PAY_ variables

DVvalues = unique(estimation_data[,dependent_variable])
x0 = estimation_data[which(estimation_data[,dependent_variable]==DVvalues[1]),boxplots_independent_variables]
x1 = estimation_data[which(estimation_data[,dependent_variable]==DVvalues[2]),boxplots_independent_variables]
colnames(x0) <- 1:ncol(x0)
colnames(x1) <- 1:ncol(x1)

swatch.default <- as.character(swatch())
set_swatch(c(swatch.default[1], colorRampPalette(RColorBrewer::brewer.pal(12, "Paired"))(ncol(x1))))
ggplot(melt(cbind.data.frame(n=1:nrow(x1), x1), id="n"), aes(x=n, y=value, colour=variable)) + geom_boxplot(fill="#FFFFFF", size=0.66, position=position_dodge(1.1*nrow(x1)))
set_swatch(swatch.default)
```

and class 0:

```{r echo=FALSE, fig.height=4.5}
swatch.default <- as.character(swatch())
set_swatch(c(swatch.default[1], colorRampPalette(RColorBrewer::brewer.pal(12, "Paired"))(ncol(x0))))
ggplot(melt(cbind.data.frame(n=1:nrow(x0), x0), id="n"), aes(x=n, y=value, colour=variable)) + geom_boxplot(fill="#FFFFFF", size=0.66, position=position_dodge(1.1*nrow(x0)))
set_swatch(swatch.default)
```
